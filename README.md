# Code for HQSS: Shadow Removal by High-Quality Shadow Synthesis [Paper](https://arxiv.org/abs/2212.04108)


## Dependencies
This code uses the following libraries
- python 3.7+
- pytorch 1.1+ & tochvision
- scikit-image
- focal-frequency-loss

## Training code and data

Generate the training data using the original ISTD dataset and the code ```gettraindata.m```

or download the training data from: GoogleDrive: [ISTD](https://drive.google.com/file/d/1az6HF6VTD6w1AcEFzW4RstAEZgjTqzPB/view?usp=sharing) | BaiduNetdisk: [ISTD](https://pan.baidu.com/s/1TppO4RqehJBh-TEIseYErA) (Access code: 1111)

Your `~/AISTD/` folder should look like this
```
AISTD
├── train/
    ├── train_A/
    │   └── 90-1.png
    │   └── ...
    ├── train_B/
    │   └── ...
    └── ...
```

## Pre-computed mask

We need to crop the original images to non-shadaow/shadow image. The suitable crop mask is computed as like [G2R-ShadowNet](https://github.com/hhqweasd/G2R-ShadowNet)

Please ensure mask pickle are exists. ```Lines 38/48``` of ```datasets_decouple.py```

You can download these pickle generated by us from [here](https://drive.google.com/file/d/17aa74FOk9qJyB8Zo4vgs3cjrIJxWoh7r/view?usp=sharing) or use ```map_dict.py``` to produce the pickle. 

## Testing masks produced by BDRAR

GoogleDrive: [ISTD](https://drive.google.com/file/d/1fx7PODULpfRD6dsatvpsNpKoHKeYks7J/view?usp=sharing)


## Train and test on the adjusted ISTD dataset

#### First, train a pseudo image generation network.

1. Set the paths: ```Lines 104/105``` of ```train_shadow_generation_network.py```
2. Set the paths: ```Lines 210-226``` of ```utils.py```
3. ```python train_shadow_generation_network.py```


#### Second, train a shadow removal network.

1. Set the paths: ```Lines 134/135/217/222``` of ```train_shadow_removal_network.py```
    
2. ```python train_shadow_removal_network.py```

#### Third, obtain test(predicted) images   
1. Set the paths: ```Lines 30-34/56/57``` of ```test.py```/```Lines 29-33/53/54``` of ```test_SRD.py```
   
2. ```python test.py/test_SRD.py```

## Evaluate
1. Set the paths of the shadow removal results and the dataset in ```evaluate.m/evaluate_SRD.m```
2. Run ```evaluate.m/evaluate_SRD.m```

## The Best Models on ISTD

GoogleDrive: [ISTD](https://drive.google.com/file/d/1uNUWZcBkxR0HT2PTdW245Nh3fISaRQtg/view?usp=sharing)

## The Best Models on SRD

GoogleDrive: [SRD](https://drive.google.com/file/d/124Lve0dDf5Bg_gamJvPrWx-L_yyGwjbj/view?usp=sharing)
 
## Results of HQSS on ISTD

GoogleDrive: [ISTD](https://drive.google.com/file/d/1JS39FrfjoNIYuiFm3tt3nipS9nRKbEWJ/view?usp=sharing)

## Results of HQSS on SRD

GoogleDrive: [ISTD](https://drive.google.com/file/d/1VzkJA0weQj4-U3VFDP8GpCCkXThPF1X-/view?usp=sharing)


## ISTD Results
| Method | Shadow Region | Non-shadow Region | All |
|:-----|:-----:|:-----:|------|
| [Le & Samaras (ECCV20)](https://github.com/lmhieu612/FSS2SR) | 10.4 | 2.9 | 4.0 |
| [G2R-ShadowNet (CVPR21)](https://github.com/hhqweasd/G2R-ShadowNet) | 8.9 | 2.9 | 3.9 |
| HQSS (Ours) | 8.48 | 2.82 | 3.72 |

Results in shadow and non-shadow regions are computed on each image first and then compute the average of all images in terms of RMSE.

## Shadow Video Results
| Method | RMSE | RMSE$_{40}$ | PSNR | SSIM |
|:-----|:-----:|:------:|------|:-----|
| [Le & Samaras (ECCV20)](https://github.com/lmhieu612/FSS2SR) | - | 20.9 | - | - |
| [G2R-ShadowNet (CVPR21)](https://github.com/hhqweasd/G2R-ShadowNet) | 21.8 | 18.8 | 21.07 | 0.882 |
| HQSS (Ours) | 18.95 | 16.82 | 21.89 | 0.888 |

RMSE$_{40}$ denotes that the moving-shadow mask is computed with a threshold of 40. Other results use the moving-shadow mask which is computed with a threshold of 80.

## Acknowledgments
Code is implemented based on [G2R-ShadowNet](https://github.com/hhqweasd/G2R-ShadowNet)

